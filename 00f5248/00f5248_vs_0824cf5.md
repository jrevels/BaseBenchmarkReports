# Benchmark Report

## Job Properties

*Commit(s):* [jrevels/julia@00f5248](https://github.com/jrevels/julia/commit/00f5248db1df66c923bb2d0d93e98a534d9cfe4b) vs [JuliaLang/julia@0824cf5](https://github.com/JuliaLang/julia/commit/0824cf5fbd7e8f99902d47cc592a45592bb7e7c1)

*Tag Predicate:* `ALL`

*Triggered By:* [link](https://github.com/jrevels/julia/pull/4#issuecomment-176405200)

## Results

Below is a table of this job's results. If available, the data used to generate this
table can be found in the JSON file in this directory.

Benchmark definitions can be found in [JuliaCI/BaseBenchmarks.jl](https://github.com/JuliaCI/BaseBenchmarks.jl).

The ratio values in the below table equal `primary_result / comparison_result` for each corresponding
metric. Thus, `x < 1.0` would denote an improvement, while `x > 1.0` would denote a regression.
Note that a default tolerance of `0.2` is applied to account for the variance of our test
hardware.

Regressions are marked with :x:, while improvements are marked with :white_check_mark:. GC
measurements are [not considered when determining regression status](https://github.com/JuliaCI/BenchmarkTrackers.jl/issues/5).

Only benchmarks with significant results - results that indicate regressions or improvements - are
shown below (an empty table means that all benchmark results remained invariant between builds).

| Group ID | Benchmark ID | time | time spent in GC | bytes allocated | number of allocations |
|----------|--------------|------|------------------|-----------------|-----------------------|

## Version Info

#### Primary Build

```
?
```

#### Comparison Build

```
?
```

## Benchmark Group List

Here's a list of all the benchmark groups executed by this job:

