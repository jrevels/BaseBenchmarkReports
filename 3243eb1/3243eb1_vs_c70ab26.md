# Benchmark Report

## Job Properties

*Commit(s):* [jrevels/julia@3243eb1](https://github.com/jrevels/julia/commit/3243eb1c21947be1828dc8a8c14256f390e60230) vs [JuliaLang/julia@c70ab26](https://github.com/JuliaLang/julia/commit/c70ab26bb677c92f0d8e0ae41c3035217a4b111f)

*Tag Predicate:* `"array"`

*Triggered By:* [link](https://github.com/jrevels/julia/commit/3243eb1c21947be1828dc8a8c14256f390e60230#commitcomment-15236196)

## Results

Below is a table of this job's results. If available, the data used to generate this
table can be found in the JSON file in this directory. Note that it's technically possible
for this JSON data to get out of sync with the below table. This would only happen in case
of a network error during the job, and as such is very unlikely. Just in case, you can always
verify that they are synced up by checking the commit history of both files.

The values in the below table are ratios of the head commit result vs. comparison commit
result for the corresponding metric. Thus, `x < 1.0` would denote an improvement, while
`x > 1.0` would denote a regression. Note, however, that a default tolerance of `0.10` is
applied when passing judgment on these results. For convenience, failures are marked with
an **{F}**.

| Benchmark ID | time | % of time spent in GC | bytes allocated | number of allocations |
|--------------|------|-----------------------|-----------------|-----------------------|

